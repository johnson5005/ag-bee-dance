###############################################################################
## 03 Analysis                                                               ##
## This script includes the inter-dance distance, k-nearest neighbor,        ##
## and K-means cluster analyses                                              ##
## Author: Bradley Ohlinger and Roger Sch√ºrch                                ##
###############################################################################

# MIT License 
# 
# Copyright (c) [2025] [Bradley Ohlinger] 
# 
# Permission is hereby granted, free of charge, to any person obtaining a copy of 
# this software and associated documentation files (the "Software"), to deal in the
# Software without restriction, including without limitation the rights to use, copy,
# modify, merge, publish, distribute, sublicense, and/or sell copies of the Software,
# and to permit persons to whom the Software is furnished to do so, subject to the
# following conditions:
# 
# The above copyright notice and this permission notice shall be included in all 
# copies or substantial portions of the Software.

# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR 
# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS
# FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR
# COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER
# IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION
# WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.

## First, we read in the data generated by the 02_analysis_prep.R, 
## which produces spatial points data frames with dance locations
## from our three sites: bb_points, tw_points, and win_points.
## If you haven't already run this script, you can run the line below
## Make sure that your working directory is set to the foraging_cluster_analysis
## folder. 

# source("./scripts/02_analysis_prep.R")

## Let's make a list containing separate date frames for each site. 
## We will use site_list and the sites vector for all three analyses.
## We will put this code before each analysis, so we can easily
## skip ahead to the other analysis (if we choose to do so).

site_list <- 
  list(blacksburg = bb_points, tidewater = tw_points,
       winchester = win_points)

sites <- c("blacksburg", "tidewater", "winchester")


## We will fill these data frames with the confidence intervals for each site
within_ci_df <- data.frame()
btw_ci_df <- data.frame()
diff_ci_df <- data.frame()


samples <- 1000
set.seed(9)

 for (site in sites){
   
   ## this loop takes in a list consisting of a spatial points data frame 
   ## for each site and then produce site-specific data that is then fed
   ## into the loop below
   
   site_data <- site_list[[site]]
   site_data$rows <- 1:length(site_data$DanceID)
   
   ## We will fill within_ci, btw_ci, and diff_ci with a mean within and between
   ## inter-dance distance (and the difference between these values) for each
   ## sample. Each value in the vector will be calculated from all of the foraging
   ## days in each sample.

within_ci <- vector() 
btw_ci <- vector()
diff_ci <- vector()
  
for (sample in 1:samples){
  
    ## this loop takes the site-specific data frame as an input and 
    ## produces a spatial points data frame consisting of 
    ## a single point for each dance from the current data/site
  
    idx <- tapply(site_data$rows, site_data$DanceID, 
                  function(x) sample(x,1))
    data <- site_data[idx,]
    data@data <- data@data[,c("easting", "northing","HiveID", "DanceID", "Date")]
    
    ## We will store the within- and between-colony inter-dance distances, and the
    ## difference between these values,for each foraging day within each sample
    ## in these vectors. We will then take the mean of these vectors for each sample
    ## after looping through each foraging day. The mean values will be stored
    ## in within_ci, btw_ci, and diff_ci.
    
    within_vector <- vector() 
    btw_vector <- vector()
    diff_vector <- vector()
    
for (date in unique(data$Date)){
  
    ## this loop selects data from each date, from each sample
    ## of a single location per dance at our current field site. 
  
    date_data <- data[data$Date == date,] ## here we select data from each 
    ## single date per sample
    
    date_data$rows <- 1:length(date_data$DanceID)
    
    ## here we randomly select a focal dance from the date_data.
    
    hive_idx <- sample(date_data$rows, 1)
    hive_data <- date_data[hive_idx,]  
    
    ## Now we sample a different dance from the same hive, and rbind the two
    ## dances together as a df.
    
    same_hive_idx <- 
      sample(date_data@data[date_data$HiveID == hive_data$HiveID &
                              date_data$DanceID != hive_data$DanceID,"rows"], 1)
    same_hive_data <- date_data[same_hive_idx, ]
    within_data <- rbind(hive_data, same_hive_data) 
    
    ## Here we select a random dance from a different hive and then rbind the
    ## focal dance and the other_hive_dance as a data frame.
    
    other_hive_idx <- 
      sample(date_data@data[date_data$HiveID != hive_data$HiveID,"rows"], 1)
    other_hive_data <- date_data[other_hive_idx, ]
    btw_data <- rbind(hive_data, other_hive_data)

    ## Now we calculate within and between dance distance for the selected dances
    ## and the difference between these values.
    
        within_dist <- pointDistance(within_data, lonlat = FALSE)
        mean_within_dist <-  mean(within_dist[within_dist != 0])
        btw_dist <- pointDistance(btw_data, lonlat = FALSE)
        mean_btw_dist <- mean(btw_dist[btw_dist != 0])
        mean_diff_dist <- mean_btw_dist - mean_within_dist
        
        if (date != tail(unique(data$Date), 1)){
          
          # if we are not on the last date of a sample 
          # we add the individual date values to the appropriate vectors
          #(within_vector, btw_vector, or diff_vector)
          
          within_vector <- c(within_vector, mean_within_dist)
          btw_vector <- c(btw_vector, mean_btw_dist)
          diff_vector <- c(diff_vector, mean_diff_dist)
          
        }else if (sample != samples){
          
          # if we are on the last date of a sample, but not the last sample
          # we add the individual date values to the appropriate vectors (within_vector,
          # btw_vector, or diff_vector) and then take the mean of those vectors and add 
          # the mean values to the appropriate vectors for calculating point estimates
          # and CIs (within_ci, btw_ci, or diff_ci)
          
          within_vector <- c(within_vector,mean_within_dist)
          within_mean <- mean(within_vector, na.rm = TRUE)
          within_ci <- c(within_ci,within_mean)
          
          btw_vector <- c(btw_vector, mean_btw_dist)
          btw_mean <- mean(btw_vector, na.rm = TRUE)
          btw_ci <- c(btw_ci, btw_mean)
          
          diff_vector <- c(diff_vector, mean_diff_dist)
          diff_mean <- mean(diff_vector, na.rm = TRUE)
          diff_ci <- c(diff_ci,diff_mean)
          
        }else{
          
          # if we are on the last sample and the last date of a sample we add
          # the individual date values to the appropriate vectors (within_vector
          # btw_vector, or diff_vector) and then take the mean of those vectors and add
          # the mean values to the appropriate vectors for calculating point
          # estimates and CIs (prop_ci or ratio_ci). We then calculate the
          # point estimates and confidence intervals and add the site name
          # to a data frame summarizing the results
          
          within_vector <- c(within_vector,mean_within_dist)
          within_mean <- mean(within_vector, na.rm = TRUE)
          within_ci <- c(within_ci,within_mean)
          within_ci_vector <-
            c(site, as.vector(quantile(within_ci, prob = c(0.50, 0.025, 0.975), na.rm = TRUE)))
          within_ci_df <- rbind(within_ci_df, within_ci_vector)
          colnames(within_ci_df) <- c("site", "median", "lwr", "upr")
          
          btw_vector <- c(btw_vector, mean_btw_dist)
          btw_mean <- mean(btw_vector, na.rm = TRUE)
          btw_ci <- c(btw_ci, btw_mean)
          btw_ci_vector <- 
            c(site, as.vector(quantile(btw_ci, prob = c(0.50, 0.025, 0.975), na.rm = TRUE)))
          btw_ci_df <- rbind(btw_ci_df, btw_ci_vector)
          colnames(btw_ci_df) <- c("site", "median", "lwr", "upr")
          
          diff_vector <- c(diff_vector, mean_diff_dist)
          diff_mean <- mean(diff_vector, na.rm = TRUE)
          diff_ci <- c(diff_ci,diff_mean)
          diff_ci_vector <- 
            c(site, as.vector(quantile(diff_ci, prob = c(0.50, 0.025, 0.975), na.rm = TRUE)))
          diff_ci_df <- rbind(diff_ci_df, diff_ci_vector)
          colnames(diff_ci_df) <- c("site", "median", "lwr", "upr")
}}}}

# and then export the data frames and CSVs
write.csv(within_ci_df, "./csv/within_df.csv")
write.csv(btw_ci_df, "./csv/btw_df.csv")
write.csv(diff_ci_df, "./csv/diff_df.csv")

## Now let's calculate approximate p-values 
## for our confidence intervals.

## Here is a function for calculating approximate p-values 
## from our confidence intervals generated from our Monte
## Carlo samples. We will also use this function for 
## confidence intervals derived from our k-nearest neighbor
## and k-means cluster analyses.

aprox.p <- function(est, lwr, upr, ratio = FALSE, type = "half") {
  # Approximate standard error
  se <- (upr - lwr) / (2 * 1.96)
  
  if (!ratio) {
    z <- est / se
  } else {
    if (type == "half") {
      z <- (est - 0.5) / se
    } else if (type == "full") {
      z <- (est - 1.0) / se
    } else {
      stop("Invalid 'type'. Use 'half' to test against 0.5 or 'full' to test against 1.")
    }
  }
  
  # Altman-Bland p-value approximation
  p <- exp(-0.717 * abs(z) - 0.416 * z^2)
  return(p)
}


## We will calculate p-values in the order that they appear in the manuscript

## Here we calculate inter-dance distance p value at PFRC

aprox.p(as.numeric(diff_ci_df[diff_ci_df$site == "blacksburg", "median"]),
        as.numeric(diff_ci_df[diff_ci_df$site == "blacksburg", "lwr"]),
        as.numeric(diff_ci_df[diff_ci_df$site == "blacksburg", "upr"]),FALSE)

# Inter-dance distance at TAREC

aprox.p(as.numeric(diff_ci_df[diff_ci_df$site == "tidewater", "median"]),
        as.numeric(diff_ci_df[diff_ci_df$site == "tidewater", "lwr"]),
        as.numeric(diff_ci_df[diff_ci_df$site == "tidewater", "upr"]),FALSE)

# Inter-dance distance at WAREC

aprox.p(as.numeric(diff_ci_df[diff_ci_df$site == "winchester", "median"]),
        as.numeric(diff_ci_df[diff_ci_df$site == "winchester", "lwr"]),
        as.numeric(diff_ci_df[diff_ci_df$site == "winchester", "upr"]),FALSE)

## Below we run a k-nearest neighbor analysis  

## We started by creating site_list and sites, but
## I placed it here again in case we want to skip 
## ahead to this analysis.

site_list <- 
  list(blacksburg = bb_points, tidewater = tw_points,
       winchester = win_points)

sites <- c("blacksburg", "tidewater", "winchester")

# We will fill our results into the following data frames.
# prop_ci_df will hold results telling us the proportional abundance
# of dances from the focal colony in the k-nearest neighbors (Neighboring Value).
# ratio_ci_df will correct for the proportional abundance of dances
# from the focal colony in the date's dataset to tell us whether
# dances from the focal colony are disproportionately represented
# as k-nearest neighbors (Neighboring Ratio). 

prop_ci_df <- data.frame()
ratio_ci_df <- data.frame()

## We set samples before the previous analysis, but I have placed it 
## here so we can change if necessary for code testing. 

samples <- 1000
set.seed(9)

## This loop takes in a list consisting of a data frame for each 
## site and then produces site-specific data that is then fed into 
## the next loop

for (site in sites){
  site_data <- site_list[[site]]
  site_data$rows <- 1:length(site_data$DanceID)
  
## These vectors will hold mean neighboring values and neighboring ratios
## calculated across all foraging days in each sample (one mean per sample).
## We will use these vectors to calculate point estimates and CIs.
  
 prop_ci <- vector()
 ratio_ci <- vector()

  for (sample in 1:samples){
    
    ## here we select a single simulated dance location per dance
    
    idx <- tapply(site_data$rows, site_data$DanceID, 
                  function(x) sample(x,1))
    data <- site_data[idx,]
    
    ## we will use "data" as an input and loop through each day
    ## we will fill these vectors with the neighboring values and 
    ## neighboring ratios calculated from each day in the current sample.
    
    prop_vector <- vector()
    ratio_vector <- vector()
    
    for (date in unique(data$Date)){
      
      ## here we subset only data from a single date, which we call date_data,
      ## and then we we select a focal dance
      
      date_data <- data[data$Date == date,]
      date_data$rows <- 1:length(date_data$DanceID)
      
      ## Now we randomly select a focal point (simulated dance location). 
      ## We then calculate the distances between the focal point and
      ## its k nearest neighbors (k = n - 1), with n being the number of dances
      ## from the focal colony on the current date.
      
      hive_idx <- sample(date_data$rows, 1)
      focal_point <-
        date_data[hive_idx,]

      hive <- unique(focal_point$HiveID)
      date_data$dist <-
        sqrt((date_data@data$easting - focal_point@data$easting)^2 +
               (date_data@data$northing - focal_point@data$northing)^2)
      
      neighbors <-
        head(date_data@data[order(date_data@data$dist),],table(date_data$HiveID)[[hive]])
      neighbors <- neighbors[neighbors$dist != 0,]
      
      ## here we calculate the proportional abundance of dances from the focal 
      ## colony as k nearest neighbors (prop, or the Neighboring Value). We then
      ## correct for the proportional abundance of the focal colony in the
      ## foraging day's data set by calculating the Neighboring Ratio. 
      
      prop <- sum(neighbors$HiveID == hive)/(table(date_data$HiveID)[[hive]] - 1)
      prop_date <- (table(date_data$HiveID)[[hive]]/length(date_data$HiveID))
      ratio <- prop/prop_date
      
      
      if (date != tail(unique(data$Date), 1)){
        
        # if we are not on the last date of a sample 
        # we add the individual date values to the appropriate vectors
        #(prop_vector or ratio_vector)
        
        prop_vector <- c(prop_vector, prop)
        ratio_vector <- c(ratio_vector, ratio)
        
      }else if (sample != samples){
        
        # if we are on the last date of a sample, but not the last sample
        # we add the individual date values to the appropriate vectors (prop_vector
        # and ratio_vector) and then take the mean of those vectors and add the 
        # mean values to the appropriate vectors for calculating point estimates
        # and CIs (prop_ci or ratio_ci)
        
        prop_vector <- c(prop_vector, prop)
        prop_mean <- mean(prop_vector)
        prop_ci <- c(prop_ci, prop_mean)
        
        ratio_vector <- c(ratio_vector, ratio)
        ratio_mean <- mean(ratio_vector)
        ratio_ci <- c(ratio_ci, ratio_mean)
        
      }else{
        
        # if we are on the last sample and the last date of a sample we add
        # the individual date values to the appropriate vectors (prop_vector
        # and ratio_vector) and then take the mean of those vectors and add
        # the mean values to the appropriate vectors for calculating point
        # estimates and CIs (prop_ci or ratio_ci). We then calculate the
        # point estimates and confidence intervals and add the site name
        # to a data frame summarizing the results
        
        prop_vector <- c(prop_vector, prop)
        prop_mean <- mean(prop_vector)
        prop_ci <- c(prop_ci, prop_mean)
        prop_ci_vector <-
          c(site, as.vector(quantile(prop_ci, prob = c(0.50, 0.025, 0.975))))
        prop_ci_df <- rbind(prop_ci_df, prop_ci_vector)
        colnames(prop_ci_df) <- c("site", "median", "lwr", "upr")
        
        ratio_vector <- c(ratio_vector, ratio)
        ratio_mean <- mean(ratio_vector)
        ratio_ci <- c(ratio_ci, ratio_mean)
        ratio_ci_vector <-
          c(site, as.vector(quantile(ratio_ci, prob = c(0.50, 0.025, 0.975))))
        ratio_ci_df <- rbind(ratio_ci_df, ratio_ci_vector)
        colnames(ratio_ci_df) <- c("site", "median", "lwr", "upr")
        
      }
     }
    }
   }

 

write.csv(prop_ci_df, "./csv/nn_prop_ci_df.csv")
write.csv(ratio_ci_df, "./csv/nn_ratio_ci_df.csv")

## Here is a function for calculating aproximate p-values 
## from our confidence intervals generated from our Monte
## Carlo samples. We defined this function after the inter-dance 
## distance analysis, but I have placed it here in case we decide
## to skip to this analysis.

aprox.p <- function(est, lwr, upr, ratio = FALSE, type = "half") {
  # Approximate standard error
  se <- (upr - lwr) / (2 * 1.96)

  if (!ratio) {
    z <- est / se
  } else {
    if (type == "half") {
      z <- (est - 0.5) / se
    } else if (type == "full") {
      z <- (est - 1.0) / se
    } else {
      stop("Invalid 'type'. Use 'half' to test against 0.5 or 'full' to test against 1.")
    }
  }

  # Altman-Bland p-value approximation
  p <- exp(-0.717 * abs(z) - 0.416 * z^2)
  return(p)
}


## We will calculate p-values in the order that they appear in the manuscript

# Neighboring value at TAREC

aprox.p(as.numeric(prop_ci_df[prop_ci_df$site == "tidewater", "median"]),
        as.numeric(prop_ci_df[prop_ci_df$site == "tidewater", "lwr"]),
        as.numeric(prop_ci_df[prop_ci_df$site == "tidewater", "upr"]),
        TRUE, "half")

# Neighboring value at WAREC

aprox.p(as.numeric(prop_ci_df[prop_ci_df$site == "winchester", "median"]),
        as.numeric(prop_ci_df[prop_ci_df$site == "winchester", "lwr"]),
        as.numeric(prop_ci_df[prop_ci_df$site == "winchester", "upr"]),
        TRUE, "half")

# Neighboring value at PFRC

aprox.p(as.numeric(prop_ci_df[prop_ci_df$site == "blacksburg", "median"]),
        as.numeric(prop_ci_df[prop_ci_df$site == "blacksburg", "lwr"]),
        as.numeric(prop_ci_df[prop_ci_df$site == "blacksburg", "upr"]),
        TRUE, "half")

# Neighboring ratio at TAREC

aprox.p(as.numeric(ratio_ci_df[ratio_ci_df$site == "tidewater", "median"]),
        as.numeric(ratio_ci_df[ratio_ci_df$site == "tidewater", "lwr"]),
        as.numeric(ratio_ci_df[ratio_ci_df$site == "tidewater", "upr"]),
        TRUE, "full")

# Neighboring Ratio at WAREC

aprox.p(as.numeric(ratio_ci_df[ratio_ci_df$site == "winchester", "median"]),
       as.numeric(ratio_ci_df[ratio_ci_df$site == "winchester", "lwr"]),
       as.numeric(ratio_ci_df[ratio_ci_df$site == "winchester", "upr"]),
       TRUE, "full")

# Neighboring ratios at PFRC

aprox.p(as.numeric(ratio_ci_df[ratio_ci_df$site == "blacksburg", "median"]),
        as.numeric(ratio_ci_df[ratio_ci_df$site == "blacksburg", "lwr"]),
        as.numeric(ratio_ci_df[ratio_ci_df$site == "blacksburg", "upr"]),
        TRUE, "full")

## K-means cluster analysis

## We started by creating site_list and sites, but
## I placed it here again in case we want to skip
## ahead to this analysis.

site_list <-
  list(blacksburg = bb_points, tidewater = tw_points,
       winchester = win_points)

sites <- c("blacksburg", "tidewater", "winchester")

## Here we create a function for selecting the optimal number of clusters
## for a sample of simulated dance locations. In this algorithm,
## we calculate the sum of the within cluster sse for k number of clusters. We start with one cluster
## and then we add clusters one by one up the k = n -1, with n being the number of dances
## in the sample. However, when n - 1 > 15, we set the max K = 15 to prevent overfitting.

opt_clust <- function(data, hives, easting, northing){
  if (nrow(data) - 1 < 15){

    y <- nrow(data) - 1

  } else {

    y <- 15

  }

  all_clust_df <- data.frame() ## this data from will be filled
  ## with the results kmeans() with 2:length(data_kmean$easting) - 1 as k.
  ## It will refill with each sample from a single date

for (k in 1:y){
  
  clust_rslt <-  kmeans(data, centers = k)
  clust_df <-
    data.frame(cluster = clust_rslt$cluster, HiveID = hives,
               easting = easting, northing = northing, num_clust = k, 
               within_ss = sum(clust_rslt$withinss))
  all_clust_df <- rbind(all_clust_df, clust_df)
  
}

within_ss <- aggregate(list(within_ss = all_clust_df$within_ss),
                       by = list(num_clust = all_clust_df$num_clust),
                       unique)
within_ss$diff <- c(NA,diff(within_ss$within_ss))
within_ss <- within_ss[-1,]

if (all(within_ss$diff < 0, na.rm = TRUE)){
  
  num <- max(within_ss[,"num_clust"], na.rm = TRUE)
  
}else if (all(within_ss$diff > 0, na.rm = TRUE)){
  
  num <- min(within_ss$num_clust)
  
}else{
  
  within_ss$sign <- ifelse(within_ss$diff > 0, "positive", "negative")
  within_ss$status <-
    ifelse(within_ss$num_clust < min(within_ss[within_ss$sign == "positive", "num_clust"], na.rm = TRUE), "include", "exclude")
  
  num <-
    max(within_ss[!is.na(within_ss$diff) &
                    within_ss$status == "include", "num_clust"])
}
return(list(all_clust_df = all_clust_df, num = num))
}


## now that we have an algorithm for selecting the optimal number of clusters,
## let's run the analysis

## We will keep count of the total number of distinct foraging territories
##, which are clusters with only dances from a single colony

territory_count <- 0

## this will count the number of runs

run_count <- 0

## this will count the number of dances

dance_count <- 0

## and total clusters

cluster_count <- 0

## We will fill these data frames with the point estimates and confidence
## intervals for all three sites.

max_prop_ci_df <- data.frame() 
prop_clust_terr_ci_df <- data.frame()
prop_hive_terr_ci_df <- data.frame()
clust_size_ci_df <- data.frame()
inter_clust_ci_df <- data.frame()
size_diff_ci_df <- data.frame()

## we set samples before the previous analyses, but I have placed it
## here for so we can change if necessary for code testing.

samples <- 1000
set.seed(9)

for (site in sites){
  
  ## this loop takes in a list consisting of a data frame for each
  ## site and then produce site-specific data that is then fed into
  ## the loop below
  
  site_data <- site_list[[site]]
  site_data$rows <- 1:length(site_data$DanceID)
  
  ## These vectors will hold mean values for each metric
  ## calculated across all foraging days in each sample (one mean per sample).
  ## We will use these vectors to calculate point estimates and CIs.
  
  max_prop_ci <- vector() 
  prop_clust_terr_ci <- vector()
  prop_hive_terr_ci <- vector()
  clust_size_ci <- vector()
  inter_clust_ci <- vector()
  size_diff_ci <- vector()
  
  for (sample in 1:samples){
    idx <- tapply(site_data$rows, site_data$DanceID,
                  function(x) sample(x,1))
    data <- site_data@data[idx,]
    
    ## data consists of a single point for each dance
    ## we will fill the vectors below with our outcomes
    ## for each date in the current sample. 
    
    max_prop_vector <- vector()
    prop_hive_terr_vector <- vector()
    prop_clust_terr_vector <- vector()
    clust_size_vector <- vector()
    inter_clust_vector <- vector()
    size_diff_vector <- vector()
    
    for (date in unique(data$Date)){
      
      ## Here we select data from the current date and
      ## then we select only the necessary,easting and
      ## northing, columns for the opt_clust(). Finally,
      ## we scale the easting and northing coordinates,
      ## which required for opt_clust.
      
      date_data <- data[data$Date == date,]
      
      ## Now let's find out which colony has the lowest number of 
      ## dances and select a subsample of dances from the other colonies of 
      ## the same size. 
      
      subset_n <- min(table(unclass(date_data$HiveID)))
      
      date_hives <-  as.data.frame(table(date_data$HiveID))
      
      date_hives <- date_hives[date_hives$Freq > 0,]
      
      full_set_hives <- date_hives[date_hives$Freq == subset_n, "Var1"]
      
      full_set <- date_data[date_data$HiveID %in% full_set_hives,]
      
      subset_hives <- date_hives[date_hives$Freq > subset_n, "Var1" ]
      
      subset_df <- data.frame()
      
      for (hive in subset_hives){
        
        subset <-  date_data[date_data$HiveID == hive,]
        subset$row <- 1:nrow(subset)
        idx <- sample(subset$row, subset_n)
        subset <- subset[idx,]
        subset_df <- rbind(subset_df, subset)
      }
      
      subset_df$row <- NULL
      
      date_subset <- rbind(full_set, subset_df)
      
      data_kmean <- date_subset[,c("easting", "northing")]
      data_kmean <- as.data.frame(apply(data_kmean, 2, FUN = "scale"))
      
      ## Now we run opt_clust(), which runs the cluster analysis
      ## and selects the optimum number of clusters.
      
      opt_clust_result <-
        opt_clust(data = data_kmean, hives = date_subset$HiveID,
                  easting = date_subset$easting, northing = date_subset$northing)
      
      ## The above function returns several outputs, one of which is a
      ## all_clust_df, which holds the results of the cluster analysis
      ## for all values of k. Below we will select the data from the
      ## the cluster analysis with the optimum number of clusters, or k.
      ## This value is stored in an output called num.
      
      opt_clust_df <-
        opt_clust_result[['all_clust_df']][opt_clust_result[['all_clust_df']]$num_clust == opt_clust_result[['num']],]
      
      ## Below we add an a column filled with the value 1. Since each row
      ## in opt_clust_df corresponds to a single dance, this column will be
      ## used to calculate the number of dances from each hive, each cluster,
      ## and each hive in each cluster.
      
      opt_clust_df$int <- 1
      
      ## this gives us the number of dances from each colony in each cluster
      
      clust_agg <-
        aggregate(list(cluster_hive_total = opt_clust_df$int),
                  by = list(cluster = opt_clust_df$cluster, hive = opt_clust_df$HiveID),
                  FUN = sum)
      
      ## this gives us the number of dances in each cluster
      
      clust_agg_2 <-
        aggregate(list(cluster_total = clust_agg$cluster_hive_total),
                  by = list(cluster = clust_agg$cluster),
                  FUN = sum)
      
      ## this gives us the number dances for each hive.
      
      clust_agg_3 <-
        aggregate(list(hive_total = clust_agg$cluster_hive_total),
                  by = list(hive = clust_agg$hive),
                  FUN = sum)
      
      ## now we use merge to put all of this information in one place
      
      clust_agg <- merge(clust_agg_2,clust_agg, by = "cluster")
      clust_agg <- merge(clust_agg_3, clust_agg, by = "hive")
      
      ## now we calculate the proportion that each colony makes up in each cluster
      
      clust_agg$prop_cluster <-
        clust_agg$cluster_hive_total/clust_agg$cluster_total
      
      ## here we determine whether a single
      ## colony makes up an entire cluster
      
      clust_agg$territory <- ifelse(clust_agg$prop_cluster == 1, 1, 0)
      
      ## here we calculate the proportion of colonies that
      ## have established at least one distinct foraging territory
      
      clust_agg$prop_hive_terr <-
        length(unique(clust_agg[clust_agg$territory == 1, "hive"]))/
        length(unique(clust_agg$hive))
      
      ## now we calculate the percentage of clusters that were foraging territories
      
      clust_agg$prop_clust_terr <-
        length(unique(clust_agg[clust_agg$territory == 1, "cluster"]))/
        length(unique(clust_agg$cluster))
      
      ## For each cluster, we need only the data for the colony with
      ## the maximum prop_cluster.
      
      max_prop_cluster_df <- aggregate(list(max_prop_cluster = clust_agg$prop_cluster),
                                       list(cluster = clust_agg$cluster), max)
      
      clust_agg <- merge(clust_agg, max_prop_cluster_df, by = "cluster")
      
      clust_agg <- clust_agg[clust_agg$prop_cluster == clust_agg$max_prop_cluster,]
      
      ## Here we do operations to calculate full analysis means
      
      ## Let's add to our dance counter so we can calculate dances per cluster
      ## We do this now because we select a subset of the data below.
      
      dance_count <- dance_count + length(opt_clust_df$cluster)
      
      ## here we add this run to the total run count for later calculations
      ## of mean number of clusters and mean number of territories etc.
      
      run_count <- run_count + 1
      
      ## Here we add the number of territories in this run to the total count
      
      territory_count <- territory_count + sum(clust_agg$territory)
      
      ## Here we add the total number clusters from the
      ## current date in our sample to our cluster count
      ## for the full analysis.
      
      cluster_count <- cluster_count + max(clust_agg$cluster)
      
      ## In this section, we calculate the maximum inter-cluster distances and
      ## minimum within cluster distance (cluster size)
      
      ## First let's cluster size
      
      focal_data <- opt_clust_df[opt_clust_df$cluster == sample(opt_clust_df$cluster, 1),]
      
      clust_size <- max(pointDistance(focal_data[,c("easting", "northing")], lonlat = FALSE), na.rm = TRUE)
      
      ## now let's do inter cluster distance
      
      other_clust <- sample(opt_clust_df[opt_clust_df$cluster != unique(focal_data$cluster), "cluster"], 1)
      
      other_data <- opt_clust_df[opt_clust_df$cluster == other_clust,]
      
      inter_clust <- min(pointDistance(focal_data[,c("easting", "northing")],
                                       other_data[,c("easting", "northing")],
                                       lonlat = FALSE), na.rm = TRUE)
      size_diff <-  clust_size - inter_clust
      
      ## Here we create the confidence intervals for our five
      ## key outcomes : max_prop (highest proportional abundance per cluster),
      ## prop_hive_terr (proportion of hives that established at least one territory),
      ## prop_clust_terr (proportion of clusters that were territories),
      ## clust_size (maximum within cluster distance),
      ## inter_clust_vector (minimum between cluster distance)
      
      if ((date != tail(unique(data$Date),1))){
        
        ## if we are not on the last date of the run, we add the values from
        ## the current date in our current sample to the appropriate
        ## vectors (max_prop_vector, prop_hive_terr_vector, prop_clust_terr_vector,
        ## clust_size_vector, inter_clust_vector, size_diff_vector)
        
        max_prop_vector <- c(max_prop_vector, clust_agg$max_prop_cluster)
        prop_hive_terr_vector <- c(prop_hive_terr_vector, mean(clust_agg$prop_hive_terr))
        prop_clust_terr_vector <- c(prop_clust_terr_vector, mean(clust_agg$prop_clust_terr))
        clust_size_vector <- c(clust_size_vector, clust_size)
        inter_clust_vector <- c(inter_clust_vector, inter_clust)
        size_diff_vector <- c(size_diff_vector, size_diff)
        
      }else if (sample != samples){
          
          max_prop_vector <- c(max_prop_vector, clust_agg$max_prop_cluster)
          max_prop_mean <- mean(max_prop_vector)
          max_prop_ci <- c(max_prop_ci, max_prop_mean)
          
          prop_hive_terr_vector <- c(prop_hive_terr_vector, mean(clust_agg$prop_hive_terr))
          prop_hive_terr_mean <- mean(prop_hive_terr_vector)
          prop_hive_terr_ci <- c(prop_hive_terr_ci,prop_hive_terr_mean)
          
          prop_clust_terr_vector <- c(prop_clust_terr_vector, mean(clust_agg$prop_clust_terr))
          prop_clust_terr_mean <- mean(prop_clust_terr_vector)
          prop_clust_terr_ci <- c(prop_clust_terr_ci,prop_clust_terr_mean )
          
          clust_size_vector <- c(clust_size_vector, clust_size)
          clust_size_mean <- mean(clust_size_vector)
          clust_size_ci <- c(clust_size_ci, clust_size_mean)
          
          inter_clust_vector <- c(inter_clust_vector, inter_clust)
          inter_clust_mean <- mean(inter_clust_vector)
          inter_clust_ci <- c(inter_clust_ci, inter_clust_mean)
          
          size_diff_vector <- c(size_diff_vector, size_diff)
          size_diff_mean <- mean(size_diff_vector)
          size_diff_ci <- c(size_diff_ci, size_diff_mean)
          
          
        }else{
          
          max_prop_vector <- c(max_prop_vector, clust_agg$max_prop_cluster)
          max_prop_mean <- mean(max_prop_vector)
          max_prop_ci <- c(max_prop_ci,max_prop_mean)
          max_prop_ci_vector <-
            c(site, as.vector(quantile(max_prop_ci, prob = c(0.50, 0.025, 0.975))))
          max_prop_ci_df <- rbind(max_prop_ci_df, max_prop_ci_vector)
          colnames(max_prop_ci_df) <- c("site", "median", "lwr", "upr")
          
          prop_hive_terr_vector <- c(prop_hive_terr_vector, mean(clust_agg$prop_hive_terr))
          prop_hive_terr_mean <- mean(prop_hive_terr_vector)
          prop_hive_terr_ci <- c(prop_hive_terr_ci,prop_hive_terr_mean)
          prop_hive_terr_ci_vector <-
            c(site, as.vector(quantile(prop_hive_terr_ci, prob = c(0.50, 0.025, 0.975))))
          prop_hive_terr_ci_df <- rbind(prop_hive_terr_ci_df, prop_hive_terr_ci_vector)
          colnames(prop_hive_terr_ci_df) <- c("site", "median", "lwr", "upr")
          
          prop_clust_terr_vector <- c(prop_clust_terr_vector, mean(clust_agg$prop_clust_terr))
          prop_clust_terr_mean <- mean(prop_clust_terr_vector)
          prop_clust_terr_ci <- c(prop_clust_terr_ci,prop_clust_terr_mean)
          prop_clust_terr_ci_vector <-
            c(site, as.vector(quantile(prop_clust_terr_ci, prob = c(0.50, 0.025, 0.975))))
          prop_clust_terr_ci_df <- rbind(prop_clust_terr_ci_df, prop_clust_terr_ci_vector)
          colnames(prop_clust_terr_ci_df) <- c("site", "median", "lwr", "upr")
          
          clust_size_vector <- c(clust_size_vector, clust_size)
          clust_size_mean <- mean(clust_size_vector)
          clust_size_ci <- c(clust_size_ci, clust_size_mean)
          clust_size_ci_vector <-
            c(site, as.vector(quantile(clust_size_ci, prob = c(0.50, 0.025, 0.975))))
          clust_size_ci_df <- rbind(clust_size_ci_df, clust_size_ci_vector)
          colnames(clust_size_ci_df) <- c("site", "median", "lwr", "upr")
          
          inter_clust_vector <- c(inter_clust_vector, inter_clust)
          inter_clust_mean <- mean(inter_clust_vector)
          inter_clust_ci <- c(inter_clust_ci, inter_clust_mean)
          inter_clust_ci_vector <-
            c(site, as.vector(quantile(inter_clust_ci, prob = c(0.50, 0.025, 0.975))))
          inter_clust_ci_df <- rbind(inter_clust_ci_df, inter_clust_ci_vector)
          colnames(inter_clust_ci_df) <- c("site", "median", "lwr", "upr")
          
          size_diff_vector <- c(size_diff_vector, size_diff)
          size_diff_mean <- mean(size_diff_vector)
          size_diff_ci <- c(size_diff_ci, size_diff_mean)
          size_diff_ci_vector <-
            c(site, as.vector(quantile(size_diff_ci, prob = c(0.50, 0.025, 0.975))))
          size_diff_ci_df <- rbind(size_diff_ci_df, size_diff_ci_vector)
          colnames(size_diff_ci_df) <- c("site", "median", "lwr", "upr")
          
}}}}

## Let's export the data frames as CSV files.

write.csv(max_prop_ci_df, "./csv/max_prop_ci.csv")
write.csv(prop_clust_terr_ci_df, "./csv/prop_clust_terr_ci.csv")
write.csv(prop_hive_terr_ci_df, "./csv/prop_hive_terr_ci.csv")
write.csv(clust_size_ci_df, "./csv/clust_size_ci.csv")
write.csv(inter_clust_ci_df, "./csv/inter_clust_size_ci.csv")
write.csv(size_diff_ci_df, "./csv/size_diff_ci.csv")

## Now let's calculate the proportion of total clusters
## in the analysis that were territories.We find here
## that 62.4% of clusters were territories.

total_prop_territory <- territory_count/cluster_count

## Now let's calculate approximate p-values
## for our confidence intervales.

## Here is a function for calculating aproximate p-values
## from our confidence intervals generated from our Monte
## Carlo samples. We defined this function in the above
## analyses, but I placed it here in case we skip ahead
## to this analysis.

aprox.p <- function(est, lwr, upr, ratio = FALSE, type = "half") {
  # Approximate standard error
  se <- (upr - lwr) / (2 * 1.96)
  
  if (!ratio) {
    z <- est / se
  } else {
    if (type == "half") {
      z <- (est - 0.5) / se
    } else if (type == "full") {
      z <- (est - 1.0) / se
    } else {
      stop("Invalid 'type'. Use 'half' to test against 0.5 or 'full' to test against 1.")
    }
  }
  
  # Altman-Bland p-value approximation
  p <- exp(-0.717 * abs(z) - 0.416 * z^2)
  return(p)
}

## We will calculate p-values in the order that they appear in the manuscript

# Clustering value at PFRC

aprox.p(as.numeric(max_prop_ci_df[max_prop_ci_df$site == "blacksburg", "median"]),
        as.numeric(max_prop_ci_df[max_prop_ci_df$site == "blacksburg", "lwr"]),
        as.numeric(max_prop_ci_df[max_prop_ci_df$site == "blacksburg", "upr"]),
        TRUE, "half")

# Clustering value at TAREC

aprox.p(as.numeric(max_prop_ci_df[max_prop_ci_df$site == "tidewater", "median"]),
        as.numeric(max_prop_ci_df[max_prop_ci_df$site == "tidewater", "lwr"]),
        as.numeric(max_prop_ci_df[max_prop_ci_df$site == "tidewater", "upr"]),
        TRUE, "half")

# Clustering value at WAREC

aprox.p(as.numeric(max_prop_ci_df[max_prop_ci_df$site == "winchester", "median"]),
        as.numeric(max_prop_ci_df[max_prop_ci_df$site == "winchester", "lwr"]),
        as.numeric(max_prop_ci_df[max_prop_ci_df$site == "winchester", "upr"]),
        TRUE, "half")

# Proportion territorial colonies at PFRC

aprox.p(as.numeric(prop_hive_terr_ci_df[prop_hive_terr_ci_df$site == "blacksburg", "median"]),
        as.numeric(prop_hive_terr_ci_df[prop_hive_terr_ci_df$site == "blacksburg", "lwr"]),
        as.numeric(prop_hive_terr_ci_df[prop_hive_terr_ci_df$site == "blacksburg", "upr"]),
        TRUE, "half")

# Proportion territorial colonies at TAREC

aprox.p(as.numeric(prop_hive_terr_ci_df[prop_hive_terr_ci_df$site == "tidewater", "median"]),
        as.numeric(prop_hive_terr_ci_df[prop_hive_terr_ci_df$site == "tidewater", "lwr"]),
        as.numeric(prop_hive_terr_ci_df[prop_hive_terr_ci_df$site == "tidewater", "upr"]),
        TRUE, "half")

# Proportion territorial colonies at WAREC

aprox.p(as.numeric(prop_hive_terr_ci_df[prop_hive_terr_ci_df$site == "winchester", "median"]),
        as.numeric(prop_hive_terr_ci_df[prop_hive_terr_ci_df$site == "winchester", "lwr"]),
        as.numeric(prop_hive_terr_ci_df[prop_hive_terr_ci_df$site == "winchester", "upr"]),
        TRUE, "half")

# Proportion single-colony clusters at PFRC

aprox.p(as.numeric(prop_clust_terr_ci_df[prop_clust_terr_ci_df$site == "blacksburg", "median"]),
        as.numeric(prop_clust_terr_ci_df[prop_clust_terr_ci_df$site == "blacksburg", "lwr"]),
        as.numeric(prop_clust_terr_ci_df[prop_clust_terr_ci_df$site == "blacksburg", "upr"]),
        TRUE, "half")

# Proportion single-colony clusters at TAREC

aprox.p(as.numeric(prop_clust_terr_ci_df[prop_clust_terr_ci_df$site == "tidewater", "median"]),
        as.numeric(prop_clust_terr_ci_df[prop_clust_terr_ci_df$site == "tidewater", "lwr"]),
        as.numeric(prop_clust_terr_ci_df[prop_clust_terr_ci_df$site == "tidewater", "upr"]),
        TRUE, "half")

# Proportion single-colony clusters at WAREC

aprox.p(as.numeric(prop_clust_terr_ci_df[prop_clust_terr_ci_df$site == "winchester", "median"]),
        as.numeric(prop_clust_terr_ci_df[prop_clust_terr_ci_df$site == "winchester", "lwr"]),
        as.numeric(prop_clust_terr_ci_df[prop_clust_terr_ci_df$site == "winchester", "upr"]),
        TRUE, "half")

## Here we calculate size diff p value at PFRC

aprox.p(as.numeric(size_diff_ci_df[size_diff_ci_df$site == "blacksburg", "median"]),
        as.numeric(size_diff_ci_df[size_diff_ci_df$site == "blacksburg", "lwr"]),
        as.numeric(size_diff_ci_df[size_diff_ci_df$site == "blacksburg", "upr"]),
        FALSE)

# size diff p value at TAREC

aprox.p(as.numeric(size_diff_ci_df[size_diff_ci_df$site == "tidewater", "median"]),
        as.numeric(size_diff_ci_df[size_diff_ci_df$site == "tidewater", "lwr"]),
        as.numeric(size_diff_ci_df[size_diff_ci_df$site == "tidewater", "upr"]),FALSE)

# size diff p value at WAREC

aprox.p(as.numeric(size_diff_ci_df[size_diff_ci_df$site == "winchester", "median"]),
        as.numeric(size_diff_ci_df[size_diff_ci_df$site == "winchester", "lwr"]),
        as.numeric(size_diff_ci_df[size_diff_ci_df$site == "winchester", "upr"]),FALSE)
